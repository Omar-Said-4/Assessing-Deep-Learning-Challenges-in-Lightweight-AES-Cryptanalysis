{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, SimpleRNN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file\n",
    "# input_file = 's_aes_Quadruplets.csv'  # Replace with your input file name\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# # Select the first 1000 records\n",
    "# df_first_10000 = df.head(3000000)\n",
    "\n",
    "# # Save the selected records to another CSV file\n",
    "# output_file = 'output_first_3000000.csv'  # Replace with your desired output file name\n",
    "# df_first_10000.to_csv(output_file, index=False)\n",
    "\n",
    "# print(f\"First 1000 records saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('output_first_5000000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>691a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key\n",
       "0  25c2\n",
       "1  af42\n",
       "2  da99\n",
       "3  5be9\n",
       "4  691a"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[['key']]\n",
    "y = y.iloc[::5].reset_index(drop=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plaintext1</th>\n",
       "      <th>ciphertext1</th>\n",
       "      <th>plaintext2</th>\n",
       "      <th>ciphertext2</th>\n",
       "      <th>plaintext3</th>\n",
       "      <th>ciphertext3</th>\n",
       "      <th>plaintext4</th>\n",
       "      <th>ciphertext4</th>\n",
       "      <th>plaintext5</th>\n",
       "      <th>ciphertext5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8d54</td>\n",
       "      <td>a26b</td>\n",
       "      <td>8282</td>\n",
       "      <td>3db3</td>\n",
       "      <td>b87c</td>\n",
       "      <td>874e</td>\n",
       "      <td>b232</td>\n",
       "      <td>d81a</td>\n",
       "      <td>afb1</td>\n",
       "      <td>659d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcce</td>\n",
       "      <td>c524</td>\n",
       "      <td>c8ba</td>\n",
       "      <td>a156</td>\n",
       "      <td>2dbe</td>\n",
       "      <td>d451</td>\n",
       "      <td>9841</td>\n",
       "      <td>21a2</td>\n",
       "      <td>c636</td>\n",
       "      <td>2fdd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912</td>\n",
       "      <td>592c</td>\n",
       "      <td>30f8</td>\n",
       "      <td>70ce</td>\n",
       "      <td>6ea8</td>\n",
       "      <td>3e94</td>\n",
       "      <td>3efd</td>\n",
       "      <td>becc</td>\n",
       "      <td>4db9</td>\n",
       "      <td>2b2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f48a</td>\n",
       "      <td>fd42</td>\n",
       "      <td>e149</td>\n",
       "      <td>a884</td>\n",
       "      <td>5fc7</td>\n",
       "      <td>e60c</td>\n",
       "      <td>fcae</td>\n",
       "      <td>0561</td>\n",
       "      <td>cc0f</td>\n",
       "      <td>15c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df05</td>\n",
       "      <td>e8d4</td>\n",
       "      <td>85b1</td>\n",
       "      <td>726b</td>\n",
       "      <td>22dd</td>\n",
       "      <td>c500</td>\n",
       "      <td>8750</td>\n",
       "      <td>3082</td>\n",
       "      <td>c98a</td>\n",
       "      <td>4e5c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  plaintext1 ciphertext1 plaintext2 ciphertext2 plaintext3 ciphertext3  \\\n",
       "0       8d54        a26b       8282        3db3       b87c        874e   \n",
       "1       bcce        c524       c8ba        a156       2dbe        d451   \n",
       "2       8912        592c       30f8        70ce       6ea8        3e94   \n",
       "3       f48a        fd42       e149        a884       5fc7        e60c   \n",
       "4       df05        e8d4       85b1        726b       22dd        c500   \n",
       "\n",
       "  plaintext4 ciphertext4 plaintext5 ciphertext5  \n",
       "0       b232        d81a       afb1        659d  \n",
       "1       9841        21a2       c636        2fdd  \n",
       "2       3efd        becc       4db9        2b2e  \n",
       "3       fcae        0561       cc0f        15c8  \n",
       "4       8750        3082       c98a        4e5c  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(['key', 'before_xor','iv'], axis=1)\n",
    "print(len(x))\n",
    "x=x.values.reshape(-1, 10)\n",
    "# # Display the result\n",
    "x = pd.DataFrame(x, columns=['plaintext1', 'ciphertext1','plaintext2',  'ciphertext2','plaintext3',  'ciphertext3','plaintext4','ciphertext4','plaintext5',  'ciphertext5'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a56d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iv\n",
       "0  a56d\n",
       "1  c695\n",
       "2  20bc\n",
       "3  2218\n",
       "4  2c10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=data[['iv']]\n",
    "z_filtered = z.iloc[::5].reset_index(drop=True)\n",
    "z_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "x['iv'] = z_filtered\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all hexadecimal entries to binary representation in the entire dataframe\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_binary(hex_number):\n",
    "    return bin(int(hex_number, 16))[2:].zfill(16)\n",
    "\n",
    "x = x.applymap(convert_to_binary)\n",
    "y = y.applymap(convert_to_binary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "plaintext_train1 = np.array([list(map(int, list(row))) for row in X_train['plaintext1'].values])\n",
    "ciphertext_train1 = np.array([list(map(int, list(row))) for row in X_train['ciphertext1'].values])\n",
    "plaintext_train2 = np.array([list(map(int, list(row))) for row in X_train['plaintext2'].values])\n",
    "ciphertext_train2 = np.array([list(map(int, list(row))) for row in X_train['ciphertext2'].values])\n",
    "plaintext_train3 = np.array([list(map(int, list(row))) for row in X_train['plaintext3'].values])\n",
    "ciphertext_train3 = np.array([list(map(int, list(row))) for row in X_train['ciphertext3'].values])\n",
    "plaintext_train4 = np.array([list(map(int, list(row))) for row in X_train['plaintext4'].values])\n",
    "ciphertext_train4 = np.array([list(map(int, list(row))) for row in X_train['ciphertext4'].values])\n",
    "plaintext_train5 = np.array([list(map(int, list(row))) for row in X_train['plaintext5'].values])\n",
    "ciphertext_train5 = np.array([list(map(int, list(row))) for row in X_train['ciphertext5'].values])\n",
    "\n",
    "plaintext_test1 = np.array([list(map(int, list(row))) for row in X_test['plaintext1'].values])\n",
    "ciphertext_test1 = np.array([list(map(int, list(row))) for row in X_test['ciphertext1'].values])\n",
    "plaintext_test2 = np.array([list(map(int, list(row))) for row in X_test['plaintext2'].values])\n",
    "ciphertext_test2 = np.array([list(map(int, list(row))) for row in X_test['ciphertext2'].values])\n",
    "plaintext_test3 = np.array([list(map(int, list(row))) for row in X_test['plaintext3'].values])\n",
    "ciphertext_test3 = np.array([list(map(int, list(row))) for row in X_test['ciphertext3'].values])\n",
    "plaintext_test4 = np.array([list(map(int, list(row))) for row in X_test['plaintext4'].values])\n",
    "ciphertext_test4 = np.array([list(map(int, list(row))) for row in X_test['ciphertext4'].values])\n",
    "plaintext_test5 = np.array([list(map(int, list(row))) for row in X_test['plaintext5'].values])\n",
    "ciphertext_test5 = np.array([list(map(int, list(row))) for row in X_test['ciphertext5'].values])\n",
    "\n",
    "iv_train = np.array([list(map(int, list(row))) for row in X_train['iv'].values])\n",
    "iv_test = np.array([list(map(int, list(row))) for row in X_test['iv'].values])\n",
    "key_train = np.array([list(map(int, list(row))) for row in y_train['key'].values])\n",
    "key_test = np.array([list(map(int, list(row))) for row in y_test['key'].values])\n",
    "# Stack the arrays to create the transformed datasets\n",
    "X_train_transformed = np.stack([plaintext_train1, ciphertext_train1,plaintext_train2,ciphertext_train2,plaintext_train3,ciphertext_train3,iv_train], axis=-1)\n",
    "X_test_transformed = np.stack([plaintext_test1, ciphertext_test1,plaintext_test2,ciphertext_test2,plaintext_test3,ciphertext_test3,iv_test], axis=-1)\n",
    "\n",
    "# For the y_train and y_test\n",
    "# concat_train = np.concatenate((key_train, iv_train), axis=1)\n",
    "# concat_test = np.concatenate((key_test, iv_test), axis=1)\n",
    "y_train_transformed = key_train[..., np.newaxis]\n",
    "y_test_transformed = key_test[..., np.newaxis]\n",
    "# arr = X_train.apply(lambda row: [[int(row['plaintext'][i]), int(row['ciphertext'][i]), int(row['iv'][i])] for i in range(16)], axis=1).to_numpy()\n",
    "\n",
    "# X_train_transformed = np.zeros((X_train.shape[0], 16, 3), dtype=int)\n",
    "# for i in range(X_train.shape[0]):\n",
    "#     for j in range(16):\n",
    "#         X_train_transformed[i, j, :] = arr[i][j]\n",
    "\n",
    "# arr = X_test.apply(lambda row: [[int(row['plaintext'][i]), int(row['ciphertext'][i]), int(row['iv'][i])] for i in range(16)], axis=1).to_numpy()\n",
    "\n",
    "# X_test_transformed = np.zeros((X_test.shape[0], 16, 3), dtype=int)\n",
    "# for i in range(X_test.shape[0]):\n",
    "#     for j in range(16):\n",
    "#         X_test_transformed[i, j, :] = arr[i][j]\n",
    "\n",
    "# arr = y_train.apply(lambda row: [[int(row['key'][i])] for i in range(16)], axis=1).to_numpy()\n",
    "\n",
    "# y_train_transformed = np.zeros((y_train.shape[0], 16,1 ), dtype=int)\n",
    "# for i in range(y_train.shape[0]):\n",
    "#     for j in range(16):\n",
    "#         y_train_transformed[i, j, :] = arr[i][j]\n",
    "\n",
    "\n",
    "\n",
    "# y_test_transformed = np.zeros((y_test.shape[0], 16,1 ), dtype=int)\n",
    "# for i in range(y_test.shape[0]):\n",
    "#     for j in range(16):\n",
    "#         y_test_transformed[i, j, :] = arr[i][j]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16, 128)           1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1600)             1486400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1639424   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,794,768\n",
      "Trainable params: 3,790,928\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# #BidirectionalRNN\n",
    "# model = keras.Sequential()\n",
    "\n",
    "# # Add a Dense layer\n",
    "# model.add(layers.Dense(128, activation='relu',input_shape=(X_train_transformed.shape[1], X_train_transformed.shape[2])))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# # Convert SimpleRNN to Bidirectional RNN\n",
    "# model.add(layers.Bidirectional(layers.SimpleRNN(800), input_shape=(X_train_transformed.shape[1], 128)))\n",
    "\n",
    "# # Add a Dense layer\n",
    "# model.add(layers.Dense(1024, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# # Add a Dense layer with Sigmoid activation\n",
    "# model.add(layers.Dense(16, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=1e-15, verbose=1)\n",
    "\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-4,clipnorm=1.0)\n",
    "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy']) # Changed accuracy metric to binary_accuracy\n",
    "# # Train the model\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16, 128)           1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1600)             1486400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1639424   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,794,768\n",
      "Trainable params: 3,790,928\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model('maybe2.h5')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, min_lr=1e-15, verbose=1)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4,clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4872 - binary_accuracy: 0.7570 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.4859 - binary_accuracy: 0.7581 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.4851 - binary_accuracy: 0.7585 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4842 - binary_accuracy: 0.7591 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4835 - binary_accuracy: 0.7595 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4825 - binary_accuracy: 0.7602 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4817 - binary_accuracy: 0.7607 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4807 - binary_accuracy: 0.7614 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4800 - binary_accuracy: 0.7617 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4790 - binary_accuracy: 0.7623 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4783 - binary_accuracy: 0.7629 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4774 - binary_accuracy: 0.7636 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4768 - binary_accuracy: 0.7639 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4758 - binary_accuracy: 0.7645 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4750 - binary_accuracy: 0.7650 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4740 - binary_accuracy: 0.7656 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.4734 - binary_accuracy: 0.7662 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4724 - binary_accuracy: 0.7666 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4716 - binary_accuracy: 0.7672 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4712 - binary_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4703 - binary_accuracy: 0.7681 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4694 - binary_accuracy: 0.7686 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4686 - binary_accuracy: 0.7691 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4681 - binary_accuracy: 0.7695 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4671 - binary_accuracy: 0.7700 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4665 - binary_accuracy: 0.7704 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.4659 - binary_accuracy: 0.7709 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4648 - binary_accuracy: 0.7715 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4640 - binary_accuracy: 0.7720 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 57s 629ms/step - loss: 0.4636 - binary_accuracy: 0.7722 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4629 - binary_accuracy: 0.7727 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 57s 639ms/step - loss: 0.4621 - binary_accuracy: 0.7733 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 57s 638ms/step - loss: 0.4613 - binary_accuracy: 0.7737 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 57s 637ms/step - loss: 0.4605 - binary_accuracy: 0.7743 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 57s 639ms/step - loss: 0.4601 - binary_accuracy: 0.7745 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 58s 640ms/step - loss: 0.4594 - binary_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 58s 644ms/step - loss: 0.4585 - binary_accuracy: 0.7755 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 58s 641ms/step - loss: 0.4580 - binary_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 57s 639ms/step - loss: 0.4571 - binary_accuracy: 0.7763 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 57s 635ms/step - loss: 0.4566 - binary_accuracy: 0.7766 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 58s 639ms/step - loss: 0.4560 - binary_accuracy: 0.7770 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 57s 638ms/step - loss: 0.4555 - binary_accuracy: 0.7774 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 57s 638ms/step - loss: 0.4547 - binary_accuracy: 0.7777 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 57s 628ms/step - loss: 0.4540 - binary_accuracy: 0.7782 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 56s 627ms/step - loss: 0.4535 - binary_accuracy: 0.7785 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 56s 625ms/step - loss: 0.4528 - binary_accuracy: 0.7789 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 56s 624ms/step - loss: 0.4522 - binary_accuracy: 0.7794 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 56s 625ms/step - loss: 0.4516 - binary_accuracy: 0.7797 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 57s 639ms/step - loss: 0.4509 - binary_accuracy: 0.7802 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 58s 643ms/step - loss: 0.4503 - binary_accuracy: 0.7806 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 57s 637ms/step - loss: 0.4498 - binary_accuracy: 0.7808 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.4490 - binary_accuracy: 0.7814 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 0.4486 - binary_accuracy: 0.7816 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4479 - binary_accuracy: 0.7820 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4472 - binary_accuracy: 0.7825 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 56s 622ms/step - loss: 0.4466 - binary_accuracy: 0.7827 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 57s 628ms/step - loss: 0.4461 - binary_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 57s 629ms/step - loss: 0.4455 - binary_accuracy: 0.7835 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 57s 635ms/step - loss: 0.4449 - binary_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4443 - binary_accuracy: 0.7843 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4437 - binary_accuracy: 0.7846 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 57s 635ms/step - loss: 0.4432 - binary_accuracy: 0.7849 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4426 - binary_accuracy: 0.7853 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 57s 637ms/step - loss: 0.4420 - binary_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 0.4416 - binary_accuracy: 0.7858 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 59s 652ms/step - loss: 0.4411 - binary_accuracy: 0.7862 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 58s 640ms/step - loss: 0.4404 - binary_accuracy: 0.7865 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 57s 638ms/step - loss: 0.4398 - binary_accuracy: 0.7871 - lr: 1.0000e-04\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4395 - binary_accuracy: 0.7871 - lr: 1.0000e-04\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 57s 635ms/step - loss: 0.4389 - binary_accuracy: 0.7874 - lr: 1.0000e-04\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4383 - binary_accuracy: 0.7878 - lr: 1.0000e-04\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 0.4379 - binary_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 57s 638ms/step - loss: 0.4371 - binary_accuracy: 0.7886 - lr: 1.0000e-04\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4364 - binary_accuracy: 0.7890 - lr: 1.0000e-04\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 0.4363 - binary_accuracy: 0.7891 - lr: 1.0000e-04\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4357 - binary_accuracy: 0.7893 - lr: 1.0000e-04\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 57s 629ms/step - loss: 0.4353 - binary_accuracy: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4346 - binary_accuracy: 0.7901 - lr: 1.0000e-04\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 57s 628ms/step - loss: 0.4342 - binary_accuracy: 0.7904 - lr: 1.0000e-04\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 57s 629ms/step - loss: 0.4336 - binary_accuracy: 0.7907 - lr: 1.0000e-04\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4332 - binary_accuracy: 0.7910 - lr: 1.0000e-04\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4327 - binary_accuracy: 0.7912 - lr: 1.0000e-04\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4319 - binary_accuracy: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4317 - binary_accuracy: 0.7918 - lr: 1.0000e-04\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4311 - binary_accuracy: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4307 - binary_accuracy: 0.7925 - lr: 1.0000e-04\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4304 - binary_accuracy: 0.7926 - lr: 1.0000e-04\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4296 - binary_accuracy: 0.7931 - lr: 1.0000e-04\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 0.4290 - binary_accuracy: 0.7935 - lr: 1.0000e-04\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 0.4288 - binary_accuracy: 0.7936 - lr: 1.0000e-04\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4283 - binary_accuracy: 0.7938 - lr: 1.0000e-04\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4277 - binary_accuracy: 0.7941 - lr: 1.0000e-04\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4275 - binary_accuracy: 0.7943 - lr: 1.0000e-04\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4269 - binary_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4265 - binary_accuracy: 0.7949 - lr: 1.0000e-04\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4259 - binary_accuracy: 0.7953 - lr: 1.0000e-04\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4253 - binary_accuracy: 0.7957 - lr: 1.0000e-04\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4250 - binary_accuracy: 0.7958 - lr: 1.0000e-04\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4247 - binary_accuracy: 0.7960 - lr: 1.0000e-04\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4243 - binary_accuracy: 0.7962 - lr: 1.0000e-04\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4239 - binary_accuracy: 0.7965 - lr: 1.0000e-04\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4232 - binary_accuracy: 0.7970 - lr: 1.0000e-04\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4230 - binary_accuracy: 0.7970 - lr: 1.0000e-04\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4227 - binary_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4220 - binary_accuracy: 0.7976 - lr: 1.0000e-04\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4215 - binary_accuracy: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4212 - binary_accuracy: 0.7981 - lr: 1.0000e-04\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4207 - binary_accuracy: 0.7984 - lr: 1.0000e-04\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4202 - binary_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4200 - binary_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4196 - binary_accuracy: 0.7991 - lr: 1.0000e-04\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4192 - binary_accuracy: 0.7992 - lr: 1.0000e-04\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4186 - binary_accuracy: 0.7996 - lr: 1.0000e-04\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4184 - binary_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4179 - binary_accuracy: 0.8000 - lr: 1.0000e-04\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4177 - binary_accuracy: 0.8001 - lr: 1.0000e-04\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4172 - binary_accuracy: 0.8005 - lr: 1.0000e-04\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4169 - binary_accuracy: 0.8006 - lr: 1.0000e-04\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4163 - binary_accuracy: 0.8011 - lr: 1.0000e-04\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4159 - binary_accuracy: 0.8012 - lr: 1.0000e-04\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4156 - binary_accuracy: 0.8014 - lr: 1.0000e-04\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4151 - binary_accuracy: 0.8017 - lr: 1.0000e-04\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4148 - binary_accuracy: 0.8019 - lr: 1.0000e-04\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4143 - binary_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4139 - binary_accuracy: 0.8024 - lr: 1.0000e-04\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4136 - binary_accuracy: 0.8026 - lr: 1.0000e-04\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4130 - binary_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4128 - binary_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4126 - binary_accuracy: 0.8031 - lr: 1.0000e-04\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4120 - binary_accuracy: 0.8035 - lr: 1.0000e-04\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4118 - binary_accuracy: 0.8035 - lr: 1.0000e-04\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4114 - binary_accuracy: 0.8039 - lr: 1.0000e-04\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4110 - binary_accuracy: 0.8042 - lr: 1.0000e-04\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4110 - binary_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4104 - binary_accuracy: 0.8044 - lr: 1.0000e-04\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4099 - binary_accuracy: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4098 - binary_accuracy: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4090 - binary_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4088 - binary_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4085 - binary_accuracy: 0.8055 - lr: 1.0000e-04\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4081 - binary_accuracy: 0.8059 - lr: 1.0000e-04\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4078 - binary_accuracy: 0.8060 - lr: 1.0000e-04\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4076 - binary_accuracy: 0.8061 - lr: 1.0000e-04\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4072 - binary_accuracy: 0.8064 - lr: 1.0000e-04\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4066 - binary_accuracy: 0.8067 - lr: 1.0000e-04\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4066 - binary_accuracy: 0.8067 - lr: 1.0000e-04\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4061 - binary_accuracy: 0.8071 - lr: 1.0000e-04\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4057 - binary_accuracy: 0.8072 - lr: 1.0000e-04\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4054 - binary_accuracy: 0.8074 - lr: 1.0000e-04\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4052 - binary_accuracy: 0.8074 - lr: 1.0000e-04\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4047 - binary_accuracy: 0.8078 - lr: 1.0000e-04\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4044 - binary_accuracy: 0.8081 - lr: 1.0000e-04\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4041 - binary_accuracy: 0.8081 - lr: 1.0000e-04\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4038 - binary_accuracy: 0.8084 - lr: 1.0000e-04\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4033 - binary_accuracy: 0.8086 - lr: 1.0000e-04\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4032 - binary_accuracy: 0.8086 - lr: 1.0000e-04\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4029 - binary_accuracy: 0.8088 - lr: 1.0000e-04\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4023 - binary_accuracy: 0.8092 - lr: 1.0000e-04\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4022 - binary_accuracy: 0.8092 - lr: 1.0000e-04\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4018 - binary_accuracy: 0.8095 - lr: 1.0000e-04\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4015 - binary_accuracy: 0.8097 - lr: 1.0000e-04\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.4013 - binary_accuracy: 0.8098 - lr: 1.0000e-04\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4011 - binary_accuracy: 0.8099 - lr: 1.0000e-04\n",
      "Epoch 164/200\n",
      "90/90 [==============================] - 57s 634ms/step - loss: 0.4005 - binary_accuracy: 0.8102 - lr: 1.0000e-04\n",
      "Epoch 165/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.4001 - binary_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 166/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3999 - binary_accuracy: 0.8107 - lr: 1.0000e-04\n",
      "Epoch 167/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3996 - binary_accuracy: 0.8109 - lr: 1.0000e-04\n",
      "Epoch 168/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3992 - binary_accuracy: 0.8111 - lr: 1.0000e-04\n",
      "Epoch 169/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3991 - binary_accuracy: 0.8111 - lr: 1.0000e-04\n",
      "Epoch 170/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3990 - binary_accuracy: 0.8112 - lr: 1.0000e-04\n",
      "Epoch 171/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3984 - binary_accuracy: 0.8114 - lr: 1.0000e-04\n",
      "Epoch 172/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3980 - binary_accuracy: 0.8116 - lr: 1.0000e-04\n",
      "Epoch 173/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3977 - binary_accuracy: 0.8119 - lr: 1.0000e-04\n",
      "Epoch 174/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3975 - binary_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 175/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3971 - binary_accuracy: 0.8122 - lr: 1.0000e-04\n",
      "Epoch 176/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3968 - binary_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 177/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3966 - binary_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 178/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3961 - binary_accuracy: 0.8128 - lr: 1.0000e-04\n",
      "Epoch 179/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3964 - binary_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 180/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3958 - binary_accuracy: 0.8129 - lr: 1.0000e-04\n",
      "Epoch 181/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3957 - binary_accuracy: 0.8131 - lr: 1.0000e-04\n",
      "Epoch 182/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3954 - binary_accuracy: 0.8132 - lr: 1.0000e-04\n",
      "Epoch 183/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3950 - binary_accuracy: 0.8135 - lr: 1.0000e-04\n",
      "Epoch 184/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3946 - binary_accuracy: 0.8136 - lr: 1.0000e-04\n",
      "Epoch 185/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3943 - binary_accuracy: 0.8138 - lr: 1.0000e-04\n",
      "Epoch 186/200\n",
      "90/90 [==============================] - 57s 632ms/step - loss: 0.3943 - binary_accuracy: 0.8139 - lr: 1.0000e-04\n",
      "Epoch 187/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3939 - binary_accuracy: 0.8141 - lr: 1.0000e-04\n",
      "Epoch 188/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3935 - binary_accuracy: 0.8143 - lr: 1.0000e-04\n",
      "Epoch 189/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3933 - binary_accuracy: 0.8144 - lr: 1.0000e-04\n",
      "Epoch 190/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3930 - binary_accuracy: 0.8146 - lr: 1.0000e-04\n",
      "Epoch 191/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3927 - binary_accuracy: 0.8148 - lr: 1.0000e-04\n",
      "Epoch 192/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3925 - binary_accuracy: 0.8149 - lr: 1.0000e-04\n",
      "Epoch 193/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3920 - binary_accuracy: 0.8151 - lr: 1.0000e-04\n",
      "Epoch 194/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3917 - binary_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 195/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3918 - binary_accuracy: 0.8153 - lr: 1.0000e-04\n",
      "Epoch 196/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3912 - binary_accuracy: 0.8156 - lr: 1.0000e-04\n",
      "Epoch 197/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3910 - binary_accuracy: 0.8157 - lr: 1.0000e-04\n",
      "Epoch 198/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3907 - binary_accuracy: 0.8159 - lr: 1.0000e-04\n",
      "Epoch 199/200\n",
      "90/90 [==============================] - 57s 630ms/step - loss: 0.3906 - binary_accuracy: 0.8160 - lr: 1.0000e-04\n",
      "Epoch 200/200\n",
      "90/90 [==============================] - 57s 631ms/step - loss: 0.3904 - binary_accuracy: 0.8162 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(X_train_transformed, y_train_transformed, epochs=200, batch_size=10000, callbacks=[reduce_lr], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 20s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = (np.array(model.predict(X_test_transformed)) >= 0.5).astype(\"int32\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_transformed=y_test_transformed.squeeze()\n",
    "y_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1]\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[2345])\n",
    "print(y_test_transformed[2345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 2\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "\n",
    "# Iterate over each array\n",
    "for i in range(y_test_transformed.shape[0]):\n",
    "    if np.array_equal(y_test_transformed[i], y_pred[i]):\n",
    "        correct_count += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "total_arrays = y_test_transformed.shape[0]\n",
    "accuracy = correct_count / total_arrays\n",
    "\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28125/28125 [==============================] - 173s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (np.array(model.predict(X_train_transformed)) >= 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed=y_train_transformed.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 110919\n",
      "Accuracy: 12.32%\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "\n",
    "# Iterate over each array\n",
    "for i in range(y_train_transformed.shape[0]):\n",
    "    if np.array_equal(y_train_transformed[i], y_pred[i]):\n",
    "        correct_count += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "total_arrays = y_train_transformed.shape[0]\n",
    "accuracy = correct_count / total_arrays\n",
    "\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1]\n",
      "[0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_transformed[0])\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('maybe2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
